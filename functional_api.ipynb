{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "The Keras _functional API_ provides a way to create models that re more flexible than `tf.keras.Sequential`. Can handle models with non-linear topology, shared layers, and even multiple inputs or outputs. \n",
    "\n",
    "Main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. The _functional API_ creates graphs of layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 784) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,))\n",
    "print(inputs.shape, inputs.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new node in the graph of layers, call the layers functiona on the `inputs` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(64, activation='relu')\n",
    "x = dense(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, 'my_first_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, evaluation, and inference \n",
    "\n",
    "Traning works exactly the same way as for the `Sequential` models. \n",
    "\n",
    "`fit()` and `evaluate()` methods are present and can be easily customized to implement traning routines beyond supervised leanring (`GAN`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = x_train.reshape(60_000, 784).astype('float32')/255\n",
    "x_test = x_test.reshape(10_000, 784).astype('float32')/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    optimizer=keras.optimizers.RMSprop(), \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "750/750 [==============================] - 7s 8ms/step - loss: 0.3506 - accuracy: 0.9019 - val_loss: 0.2093 - val_accuracy: 0.9408\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.1677 - accuracy: 0.9500 - val_loss: 0.1361 - val_accuracy: 0.9598\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.1326 - accuracy: 0.9598\n",
      "Test loss: 0.13257351517677307\n",
      "Test accuracy: 0.9598000049591064\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Serialize \n",
    "\n",
    "Saving the model and serialization works the same way for model built with the _functional API_.\n",
    "\n",
    "`model.save()`: file includes model architecture, model weight values, model training config (passed to `model.compile`), aptimizer and its state, restart training where you left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/my_first_model_training\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./models/my_first_model_training')\n",
    "del model \n",
    "model = keras.models.load_model('./models/my_first_model_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining multiple models with the same graph of layers \n",
    "\n",
    "In the functional API, models are created by specifying their inputs and outputs in a graph of layers. A single graph of layers can be used to generate multiple models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_4 (Glob (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28,28,1), name='img')\n",
    "x = layers.Conv2D(16,3, activation='relu')(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x =layers.MaxPooling2D(3)(x) \n",
    "x = layers.Conv2D(32, 3, activation='relu')(x) \n",
    "x = layers.Conv2D(16, 3, activation='relu')(x) \n",
    "encoder_output = layers.GlobalMaxPool2D()(x) \n",
    "\n",
    "encoder = keras.Model(inputs=encoder_input, outputs=encoder_output, name=\"encoder\")\n",
    "encoder.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Reshape((4,4,1))(encoder_output) \n",
    "x = layers.Conv2DTranspose(16,3, activation='relu')(x) \n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu')(x) \n",
    "x = layers.UpSampling2D(3)(x) \n",
    "x = layers.Conv2DTranspose(16,3, activation='relu')(x) \n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_4 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = keras.Model(inputs=encoder_input, outputs=decoder_output, name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All models are callable (just like layers)\n",
    "\n",
    "You can treat any modle as if it were a layer by invoking it on an `Input` or on the output of another layer. By calling a model you aren't just reusing the architecture of the mode, you are also reusing its weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "original_img (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_5 (Glob (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28,28,1), name='original_img')\n",
    "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPool2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x) \n",
    "x = layers.Conv2D(16, 3, activation='relu')(x) \n",
    "encoder_output = layers.GlobalMaxPool2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_img (InputLayer)     [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DT (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DT (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 9,569\n",
      "Trainable params: 9,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_input = keras.Input(shape=(16,), name='encoder_img')\n",
    "x = layers.Reshape((4,4,1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu')(x) \n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "decoder_output = layers.Conv2DTranspose(1,3, activation='relu')(x) \n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 16)                18672     \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 28, 28, 1)         9569      \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_input = keras.Input(shape=(28,28,1), name='img')\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate Complex graph Topologies\n",
    "\n",
    "Functional API makes it easy to manipulate multiple inputs and outputs that cannot be handled with the `Sequential` API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Building a system for ranking customer issue tickets by priority and routing them to the correct department. Modeli with have three iputs: \n",
    "\n",
    "1. Title of the ticket (text input);\n",
    "2. Text body (text input);\n",
    "3. any tags added by the user (categorical). \n",
    "\n",
    "Model will have 2 outputs: \n",
    "1. Prority score between 0 and 1 (scaler sigmoid), and \n",
    "2. the department that should handle the ticket (softmax output over the set of departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12 # num of unique issue tags \n",
    "num_words = 10_000 # size of vocabulary obtained when proprocessing text data \n",
    "num_departments = 4 # number of departments for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_input = keras.Input(\n",
    "    shape=(None,), name='title'\n",
    ") # variable-length sequence of ints \n",
    "\n",
    "body_input = keras.Input(\n",
    "    shape=(None,), \n",
    "    name='body'\n",
    ") # variable-length sequence of ints \n",
    "\n",
    "tags_input = keras.Input(\n",
    "    shape=(num_tags,), name='tags' \n",
    ") # Binary vectors of size `num_tags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed each word in the title into a 64-dimensional vector \n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "\n",
    "# Embed each word in the text into a 64-dimension vector \n",
    "body_features = layers.Embedding(num_words, 64)(body_input) \n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector \n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "\n",
    "# Reduce the sequence of embedded words in the body into a single 32-dimensional vector \n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stick a logistic regression for priority prediction on top of the features \n",
    "prority_pred = layers.Dense(1, name='priority')(x)\n",
    "\n",
    "# Stick a department classifier on top of the features \n",
    "department_pred = layers.Dense(num_departments, name='department')(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end to end model predicting both priority and department \n",
    "model = keras.Model(\n",
    "    inputs=[title_input, body_input, tags_input], \n",
    "    outputs=[prority_pred, department_pred]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When compiling the model, you can assign different losses to each output. You can also assign different weights to each loss (to modulate their contribution to the total training loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3), \n",
    "    loss=[\n",
    "        keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "        keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    ], \n",
    "    loss_weights=[1.0, 0.2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the different names assigned to each output, the losses can be assgiend based on those values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3), \n",
    "    loss={\n",
    "        'priority': keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "        'department': keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    }, \n",
    "    loss_weights={'priority': 1.0, 'department': 0.2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with dummy data \n",
    "title_data = np.random.randint(num_words, size=(1280,10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype('float32')\n",
    "\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40/40 [==============================] - 21s 24ms/step - loss: 1.4435 - priority_loss: 0.7011 - department_loss: 3.7116\n",
      "Epoch 2/2\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 1.4154 - priority_loss: 0.6992 - department_loss: 3.5810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f4a617dc0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    {'title': title_data, 'body': body_data, 'tags': tags_data}, \n",
    "    {'priority': priority_targets, 'department': dept_targets}, \n",
    "    epochs=2, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy ResNet Model \n",
    "also easy to manipulate non-linear connectivity topologies (these are models with layers that ar enot connected sequentially). Common use case is the Resnet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32,32,3), name='img')\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "block1_output = layers.MaxPool2D(3)(x) \n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block1_output)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x) \n",
    "block_2_output = layers.add([x, block1_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation='relu')(block_3_output)\n",
    "x = layers.GlobalAveragePooling2D()(x) \n",
    "x = layers.Dense(256, activation='relu')(x) \n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"toy_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 30, 30, 32)   896         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 64)   18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 9, 9, 64)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 64)     36928       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 64)     36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 9, 9, 64)     0           conv2d_3[0][0]                   \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 9, 9, 64)     36928       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 9, 9, 64)     36928       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 9, 9, 64)     0           conv2d_5[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 64)     36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          16640       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2570        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs, outputs, name='toy_resnet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"mini_resnet.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0 \n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3), \n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 2.2715 - acc: 0.1287 - val_loss: 2.1557 - val_acc: 0.1750\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 2.3455 - acc: 0.1562 - val_loss: 2.1442 - val_acc: 0.2000\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 2.1322 - acc: 0.1762 - val_loss: 2.1794 - val_acc: 0.1450\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 2.1695 - acc: 0.1875 - val_loss: 2.1000 - val_acc: 0.2050\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 2.1442 - acc: 0.1688 - val_loss: 2.0825 - val_acc: 0.1650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28fc41f18b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train[:1_000], y_train[:1_000], batch_size=64, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b203e1dbec2aedf01a1f5462c8bcde5a35074e5e5d04341a9ee3b88b6f2674e6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('keras_functional-_MSxnM2L': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
